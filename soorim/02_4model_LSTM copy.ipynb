{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02682205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4176, 144, 1) (4176, 1)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_6 (LSTM)               (None, 144, 64)           16896     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 144, 64)           0         \n",
      "                                                                 \n",
      " lstm_7 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,345\n",
      "Trainable params: 29,345\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "66/66 [==============================] - ETA: 0s - loss: 0.0633"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# ------------------------------\n",
    "# 1) 데이터 로드\n",
    "# ------------------------------\n",
    "train_df = pd.read_csv('../finalData/Uljin_04.csv')\n",
    "test_df  = pd.read_csv('../finalData/Uljin_05.csv')\n",
    "\n",
    "# timestamp를 datetime으로\n",
    "train_df['datetime'] = pd.to_datetime(train_df['datetime'])\n",
    "test_df['datetime']  = pd.to_datetime(test_df['datetime'])\n",
    "\n",
    "# 시계열 정렬\n",
    "train_df = train_df.sort_values('datetime')\n",
    "test_df  = test_df.sort_values('datetime')\n",
    "\n",
    "# ------------------------------\n",
    "# 2) 스케일링\n",
    "# ------------------------------\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "train_scaled = scaler.fit_transform(train_df[['wind_dir']])\n",
    "test_scaled  = scaler.transform(test_df[['wind_dir']])\n",
    "\n",
    "# ------------------------------\n",
    "# 3) 시퀀스 생성 함수\n",
    "# ------------------------------\n",
    "def create_sequences(data, seq_length):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "seq_length = 144  # 하루치 (10분 단위 데이터)\n",
    "\n",
    "X_train, y_train = create_sequences(train_scaled, seq_length)\n",
    "X_test, y_test   = create_sequences(test_scaled, seq_length)\n",
    "\n",
    "# LSTM 입력 shape: (samples, time_steps, features)\n",
    "print(X_train.shape, y_train.shape)  # (samples, 144, 1)\n",
    "\n",
    "# ------------------------------\n",
    "# 4) LSTM 모델\n",
    "# ------------------------------\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, input_shape=(seq_length, 1)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(32))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# ------------------------------\n",
    "# 5) 학습\n",
    "# ------------------------------\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=30,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "# ------------------------------\n",
    "# 6) 예측\n",
    "# ------------------------------\n",
    "y_pred_scaled = model.predict(X_test)\n",
    "\n",
    "# y_pred_scaled, y_test는 (samples, 1) 형태임\n",
    "# 스케일링 해제 (inverse_transform)\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "y_true = scaler.inverse_transform(y_test)\n",
    "\n",
    "# 모델 저장\n",
    "model.save('./model/Uljin/lstm_model_windDir.h5')\n",
    "\n",
    "# 스케일러 저장\n",
    "import joblib\n",
    "joblib.dump(scaler, './scaler/Uljin/windDir_scaler.pkl')\n",
    "\n",
    "# ------------------------------\n",
    "# 7) 평가 지표 계산\n",
    "# ------------------------------\n",
    "\n",
    "# MAE (평균 절대 오차)\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "# RMSE (평균 제곱근 오차)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "# MAPE (평균 절대 백분율 오차)\n",
    "mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "print(f\"Test MAE:  {mae:.3f}\")\n",
    "print(f\"Test RMSE: {rmse:.3f}\")\n",
    "print(f\"Test MAPE: {mape:.2f}%\")\n",
    "\n",
    "# ------------------------------\n",
    "# 8) 시각화\n",
    "# ------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(y_true[:500], label='Actual')   # 일부만 plot\n",
    "plt.plot(y_pred[:500], label='Predicted')\n",
    "plt.title('LSTM Forecast vs Actual (Test)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13b1269",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kosmo\\.conda\\envs\\myvenv3.9\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (4176, 144, 1)\n",
      "131/131 [==============================] - 4s 23ms/step\n",
      "Prediction shape: (4176, 1)\n",
      "✅ Shifted timestamp 시작: 2025-06-01 00:00:00\n",
      "✅ Shifted timestamp 끝: 2025-06-29 23:50:00\n",
      "\n",
      "✅ 예측 결과 저장: ./pred/this_InCheon_06.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kosmo\\AppData\\Local\\Temp\\ipykernel_5408\\3825133962.py:56: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  date_range_full = pd.date_range(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "# -------------------------------\n",
    "# 1) 작년 6월 데이터 불러오기\n",
    "# -------------------------------\n",
    "df_last_june = pd.read_csv('../finalData/InCheon_06.csv')\n",
    "df_last_june['datetime'] = pd.to_datetime(df_last_june['datetime'])\n",
    "df_last_june = df_last_june.sort_values('datetime')\n",
    "\n",
    "# -------------------------------\n",
    "# 2) 스케일러 & 모델 불러오기 (이미 저장했다고 가정)\n",
    "# -------------------------------\n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('./model/InCheon/lstm_model_pressure.h5')\n",
    "scaler = joblib.load('./scaler/InCheon/pressure_scaler.pkl')\n",
    "\n",
    "# -------------------------------\n",
    "# 3) 작년 데이터로 시퀀스 만들기\n",
    "# -------------------------------\n",
    "data_last_scaled = scaler.transform(df_last_june[['pressure']].values)\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    X = []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "    return np.array(X)\n",
    "\n",
    "seq_length = 144  # 하루치\n",
    "\n",
    "X_input = create_sequences(data_last_scaled, seq_length)\n",
    "\n",
    "print(\"Input shape:\", X_input.shape)\n",
    "\n",
    "# -------------------------------\n",
    "# 4) 예측\n",
    "# -------------------------------\n",
    "y_pred_scaled = model.predict(X_input)\n",
    "y_pred = scaler.inverse_transform(y_pred_scaled)\n",
    "\n",
    "print(\"Prediction shape:\", y_pred.shape)\n",
    "\n",
    "# -------------------------------\n",
    "# 5) 올해 6월 datetime 생성\n",
    "# -------------------------------\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "start_this_year = datetime(2025, 6, 1, 0, 0, 0)\n",
    "\n",
    "n_total_points = len(df_last_june)\n",
    "\n",
    "date_range_full = pd.date_range(\n",
    "    start=start_this_year,\n",
    "    periods=n_total_points,\n",
    "    freq='10T'\n",
    ")\n",
    "\n",
    "n_predictions = len(y_pred)\n",
    "date_range = date_range_full[seq_length : seq_length + n_predictions]\n",
    "\n",
    "date_range_shifted = date_range - pd.Timedelta(days=1)\n",
    "\n",
    "print(\"✅ Shifted timestamp 시작:\", date_range_shifted[0])\n",
    "print(\"✅ Shifted timestamp 끝:\", date_range_shifted[-1])\n",
    "\n",
    "assert len(date_range) == len(y_pred), f\"Length mismatch: {len(date_range)} vs {len(y_pred)}\"\n",
    "\n",
    "# -------------------------------\n",
    "# 6) 새 파일에 저장\n",
    "# -------------------------------\n",
    "# forecast_df = pd.DataFrame({\n",
    "#     'datetime': date_range_shifted,\n",
    "#     'sea_high': y_pred.flatten()\n",
    "# })\n",
    "forecast_df = pd.read_csv(\"./pred/this_InCheon_06.csv\")\n",
    "forecast_df['pressure'] = y_pred.flatten()\n",
    "\n",
    "forecast_df.to_csv('./pred/this_InCheon_06.csv', index=False)\n",
    "print(\"\\n✅ 예측 결과 저장: ./pred/this_InCheon_06.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
